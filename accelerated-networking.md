# AI 데이터센터 관점에서 NVIDIA의 네트워킹 솔루션 #


<u>### 1. 데이터 센터에서의 네트워킹 ###</u>

|항목|AI 팩토리| AI 클라우드|
|----|---------|--------|
|주요 항목| 대규모 언어 모델(LLM) 훈련| 다수 사용자를 지원하는 초대형(Hyperscale) 시스템|
|         | 디지털 트윈 등 고성능 연산 작업 |  멀티 테넌트 환경 제공 |
|         | AI 슈퍼컴퓨터 구축을 통한 거대·복잡한 AI 모델 훈련 및 최적화 | 상대적으로 덜 복잡한 소규모 작업 실행 |
|연산 성능 요구| 매우 높은 연산 성능 요구 | 상대적으로 낮은 연산 성능 요구 |
|네트워크 구성| 전용 네트워크 필요 | 이더넷(Ethernet) 기반 네트워크 활용 |
|            | 서버 내 DPU 간 통신: NVLink |멀티 테넌트 환경 운영  |
|            | 서버 간 GPU 통신: Infiniband |  |

### 2. 기존 네트워크의 한계와 NVIDIA의 해결책 ###

1) 기존 네트워크 한계
   * AI 워크로드는 기존 클라우드 및 인터넷 인프라에서 실행할 경우, 대량의 네트워크 트래픽을 생성하여 네트워크 인프라에 큰 영향을 미침.
   * 이로 인해 혼잡(Congestion), 지연 증가(Latency), 대역폭 불균형(Bandwidth Unfairness) 문제가 발생헤 시스템의 GPU를 효율적으로 활용하지 못함

2) NVIDIA 네트워크 해결책
   * Quantum Infiniband – 대규모 AI 팩토리를 위한 초고성능 네트워크
   * Spectrum-X Ethernet – 생성형 AI 클라우드(Generative AI Cloud) 가속을 위한 솔루션

### 3. Quantum Infiniband ###
  * 정의 : 딥러닝, 과학연산, AI 추론, 고성능 컴퓨팅(HPC) 환경을 대상으로 데이터 집약적인 시뮬레이션, 분석 애플리케이션, HPC, 슈퍼컴퓨팅에 최적화된 네트워크
  * 주요 특징
      * 400Gbps의 초고속 대역폭(NDR) 지원
      * 업계 최저 수준의 지연 증가(Latency)
      * QoS(Quality of Service), 적응형 라우팅(Adaptive Routing), 혼잡 제어(Congestion Control) 지원
      * 하드웨어 기반 RDMA를 통해 CPU 개입 없이 데이터 이동 가능
      * 32배의 AI 가속 성능 및 최대 6.5배의 확장성 향상
      * 투자 대비 효과(ROI) 및 전반적인 투자 가치 개선

### 4. Spectrum-X Ethernet ###
  * 정의 :
      * 생성형 AI 클라우드 가속을 위해 설계된 최초의 이더넷 플랫폼
      * Spectrum-X를 기반으로 한 전용 패브릭 구축은 새로운 AI 클라우드를 구현하려는 고객들에게 최적의 선택
  * 장점
      * 95%의 네트워크 효율적인 대역폭
      * 전통적인 이더넷 대비 1.6배 증가한 AI 네트워크 성능

### 5. NVIDIA 네트워크 플랫폼 ###
  * 
