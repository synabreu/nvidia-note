# AI 데이터센터 관점에서 NVIDIA의 네트워킹 솔루션 #


### 1. 데이터 센터에서의 네트워킹 ###

|항목|AI 팩토리| AI 클라우드|
|----|---------|--------|
|주요 항목| 대규모 언어 모델(LLM) 훈련| 다수 사용자를 지원하는 초대형(Hyperscale) 시스템|
|         | 디지털 트윈 등 고성능 연산 작업 |  멀티 테넌트 환경 제공 |
|         | AI 슈퍼컴퓨터 구축을 통한 거대·복잡한 AI 모델 훈련 및 최적화 | 상대적으로 덜 복잡한 소규모 작업 실행 |
|연산 성능 요구| 매우 높은 연산 성능 요구 | 상대적으로 낮은 연산 성능 요구 |
|네트워크 구성| 전용 네트워크 필요 | 이더넷(Ethernet) 기반 네트워크 활용 |
|            | 서버 내 DPU 간 통신: NVLink |멀티 테넌트 환경 운영  |
|            | 서버 간 GPU 통신: Infiniband |  |

### 2. 기존 네트워크의 한계와 NVIDIA의 해결책 ###

1) 기존 네트워크 한계
   * AI 워크로드는 기존 클라우드 및 인터넷 인프라에서 실행할 경우, 대량의 네트워크 트래픽을 생성하여 네트워크 인프라에 큰 영향을 미침.
   * 이로 인해 혼잡(Congestion), 지연 증가(Latency), 대역폭 불균형(Bandwidth Unfairness) 문제가 발생헤 시스템의 GPU를 효율적으로 활용하지 못함

2) NVIDIA 네트워크 해결책
   * Quantum Infiniband – 대규모 AI 팩토리를 위한 초고성능 네트워크
   * Spectrum-X Ethernet – 생성형 AI 클라우드(Generative AI Cloud) 가속을 위한 솔루션

### 3. Quantum Infiniband ###

