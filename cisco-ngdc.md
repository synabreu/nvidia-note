
### 1. 서버 전력 소비와 데이터센터 전환의 어려움 ###

  1) 개요
     * Intel Gaudi2 기반의 256 GPU 클러스터로 운영
     * 랙당 1개의 서버만 배치
    
  2) 전력 소비량에 따른 네트워크 문제 발생
     * H100은 약 10-11KW 전력 소모, 만약 H200 모델이면 14Kw 소모
     * 고민 :  어떤 네트워크를 구성해야 하는지, 어떤 길이의 케이블을 사용해야 하는지 결정해야 함.
     * 문제 해결 : 증된 솔루션을 제공하는 것뿐만 아니라, 이를 자동화된 운영 환경(Automated Operations)으로 구축

### 2. 256x GPU 클러스터의 운영 및 관리 방식 ###

  1) 256 GPU 클러스터는 단일 컴퓨터(Single Computer)처럼 작동함. 따라서, 하나의 구성 요소라도 문제가 발생하면 전체 훈 작업(Training Job)이 중단 =>  운영 환경에 대한 가시성(Visibility)이 필수적
  2) 케이블링(Cabling)에 2주가 소요되는 환경을 8시간 내에 구축할 수 있도록 최적화
     * AI 인프라 환경에서 256 GPU 클러스터를 구축할 때 네트워크 및 전력 케이블을 설치하는 과정
     * 네트워크 케이블링(Network Cabling) : GPU 서버 간 통신을 위한 네트워크 케이블 연결, InfiniBand, Ethernet(400G) 등의 고속 데이터 전송 케이블 사용 가능, Inter-GPU 네트워크 및 데이터센터 네트워크의 연결 방식 최적화
     * 전력 케이블링(Power Cabling) : GPU 서버 및 네트워크 장비에 전력을 공급하기 위한 케이블 연결, 고성능 GPU 서버는 랙당 10~14kW 이상의 전력을 소비하므로, 전력 배선이 매우 중요함
     * 케이블 길이 및 배치 문제 : AI/ML 워크로드를 위한 클러스터에서는 GPU 서버들이 여러 네트워크 스위치에 동시에 연결되어야 함, 따라서 랙 간 케이블 길이가 길어질 수 있으며, 이로 인해 배선 설계(Topology)가 복잡해질 수 있음, 특히, 스파인-리프(Spine-Leaf) 아키텍처에서 서버들이 여러 스위치에 연결되는 방식이 다르므로 케이블 배치가 중요한 요소임
  3) 케이블링이 중요한 이유
     * 일반적인 256 GPU 클러스터 구축 시, 물리적인 배선 작업만 3주가 걸릴 수 있음
     * Cisco에서는 자동화된 배포 및 최적화된 설계를 통해 이를 8시간 내로 단축
  4) 프로덕션 환경 검증
     * 서버 배포(Server Deployment)
     * 라이브러리 컴파일(Library Compilation, 약 2~3시간 소요)
     * 운영 자동화 설정(Operations Automation Setup) - CI/CD

### 3. 클러스터 네트워크 설계: 네트워크 엔지니어를 위한 개요 ###

  1) 서버의 네트워크 구성 - 여러 개의 전용 포트(Dedicated Ports)
  2) 인터 GPU 통신용 포트(Inter-GPU Connectivity Ports) : 서버 내부에서 GPU 간 데이터 교환이 이루어지는 전용 네트워크. 고성능 분산 학습(Distributed Training) 환경
  3) 프런트엔드 네트워크(Front-End Network) : 일반적인 데이터센터 LAN 환경과 유사한 역할
  4) 스토리지 네트워크(Storage Network) : 공유 파일 시스템(Shared File System)을 통해 GPU 서버들이 데이터를 공유하는 네트워크
  5) 관리 네트워크(Management Network) : 서버 및 네트워크 장치의 원격 관리(Remote Management) 전용 네트워크

### 4. Inter-GPU 네트워크 설계 ###

  1) 현재의 Inter-GPU 네트워크 설계는 기존의 스파인-리프(Spine-Leaf) 네트워크 구조를 기반 => 대규모 분산 학습에서 발생할 수 있는 네트워크 병목 현상(Congestion)을 방지
  2) 스파인-리프(Spine-Leaf) :
  3) Non-Blocking 네트워크 설계 : 트래픽이 차단되지 않도록 네트워크를 구성, 예) 64포트 스위치를 사용하면, 32포트는 서버에 연결되고, 나머지 32포트는 상위 스위치(Spine)에 연결됨.
  4) 레이어 최적화 설계(Railed-Optimized Design) : GPU 서버들이 여러 개의 네트워크 스위치와 연결되는 방식 최적화, 예) 첫 번째 포트는 리프 스위치 1에 연결, 두 번째 포트는 리프 스위치 2에 연결
